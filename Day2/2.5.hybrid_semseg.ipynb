{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hybrid CNN - CRF semantic segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Written by Dr Daniel Buscombe, Northern Arizona University\n",
    "\n",
    "> Part of a series of notebooks for image recognition and classification using deep convolutional neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import os, time, sys\n",
    "from glob import glob\n",
    "from scipy.misc import imread\n",
    "\n",
    "#numerical\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from scipy.io import savemat, loadmat\n",
    "import pydensecrf.densecrf as dcrf\n",
    "from pydensecrf.utils import create_pairwise_bilateral, unary_from_labels, unary_from_softmax\n",
    "from numpy.lib.stride_tricks import as_strided as ast\n",
    "import random, string\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# suppress divide and invalid warnings\n",
    "np.seterr(divide='ignore')\n",
    "np.seterr(invalid='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plotting libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import matplotlib.colors as colors\n",
    "from scipy.misc import imresize\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define subfunctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "def id_generator(size=6, chars=string.ascii_uppercase + string.digits):\n",
    "   return ''.join(random.choice(chars) for _ in range(size))\n",
    "\n",
    "# =========================================================\n",
    "def norm_shape(shap):\n",
    "   '''\n",
    "   Normalize numpy array shapes so they're always expressed as a tuple,\n",
    "   even for one-dimensional shapes.\n",
    "   '''\n",
    "   try:\n",
    "      i = int(shap)\n",
    "      return (i,)\n",
    "   except TypeError:\n",
    "      # shape was not a number\n",
    "      pass\n",
    "\n",
    "   try:\n",
    "      t = tuple(shap)\n",
    "      return t\n",
    "   except TypeError:\n",
    "      # shape was not iterable\n",
    "      pass\n",
    "\n",
    "   raise TypeError('shape must be an int, or a tuple of ints')\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# Return a sliding window over a in any number of dimensions\n",
    "# version with no memory mapping\n",
    "def sliding_window(a,ws,ss = None,flatten = True):\n",
    "    '''\n",
    "    Return a sliding window over a in any number of dimensions\n",
    "    '''\n",
    "    if None is ss:\n",
    "        # ss was not provided. the windows will not overlap in any direction.\n",
    "        ss = ws\n",
    "    ws = norm_shape(ws)\n",
    "    ss = norm_shape(ss)\n",
    "    # convert ws, ss, and a.shape to numpy arrays\n",
    "    ws = np.array(ws)\n",
    "    ss = np.array(ss)\n",
    "    shap = np.array(a.shape)\n",
    "    # ensure that ws, ss, and a.shape all have the same number of dimensions\n",
    "    ls = [len(shap),len(ws),len(ss)]\n",
    "    if 1 != len(set(ls)):\n",
    "        raise ValueError(\\\n",
    "        'a.shape, ws and ss must all have the same length. They were %s' % str(ls))\n",
    "\n",
    "    # ensure that ws is smaller than a in every dimension\n",
    "    if np.any(ws > shap):\n",
    "        raise ValueError(\\\n",
    "        'ws cannot be larger than a in any dimension.\\\n",
    " a.shape was %s and ws was %s' % (str(a.shape),str(ws)))\n",
    "    # how many slices will there be in each dimension?\n",
    "    newshape = norm_shape(((shap - ws) // ss) + 1)\n",
    "    # the shape of the strided array will be the number of slices in each dimension\n",
    "    # plus the shape of the window (tuple addition)\n",
    "    newshape += norm_shape(ws)\n",
    "    # the strides tuple will be the array's strides multiplied by step size, plus\n",
    "    # the array's strides (tuple addition)\n",
    "    newstrides = norm_shape(np.array(a.strides) * ss) + a.strides\n",
    "    a = ast(a,shape = newshape,strides = newstrides)\n",
    "    if not flatten:\n",
    "        return a\n",
    "    # Collapse strided so that it has one more dimension than the window.  I.e.,\n",
    "    # the new array is a flat list of slices.\n",
    "    meat = len(ws) if ws.shape else 0\n",
    "    firstdim = (np.product(newshape[:-meat]),) if ws.shape else ()\n",
    "    dim = firstdim + (newshape[-meat:])\n",
    "    # remove any dimensions with size 1\n",
    "    #dim = filter(lambda i : i != 1,dim)\n",
    "\n",
    "    return a.reshape(dim), newshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "def load_graph(model_file):\n",
    "  graph = tf.Graph()\n",
    "  graph_def = tf.GraphDef()\n",
    "\n",
    "  with open(model_file, \"rb\") as f:\n",
    "    graph_def.ParseFromString(f.read())\n",
    "  with graph.as_default():\n",
    "    tf.import_graph_def(graph_def)\n",
    "\n",
    "  return graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the function that actually does the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "def getCP(tmp, graph):\n",
    "  \n",
    "   #graph = load_graph(classifier_file)\n",
    "\n",
    "   input_name = \"import/Placeholder\" #input\" \n",
    "   output_name = \"import/final_result\" \n",
    "\n",
    "   input_operation = graph.get_operation_by_name(input_name);\n",
    "   output_operation = graph.get_operation_by_name(output_name);\n",
    "\n",
    "   with tf.Session(graph=graph) as sess:\n",
    "      results = sess.run(output_operation.outputs[0],\n",
    "                      {input_operation.outputs[0]: np.expand_dims(tmp, axis=0)})\n",
    "   results = np.squeeze(results)\n",
    "\n",
    "   # Sort to show labels of first prediction in order of confidence\n",
    "   top_k = results.argsort()[-len(results):][::-1]\n",
    "\n",
    "   return top_k[0], results[top_k[0]], results[top_k] #, np.std(tmp[:,:,0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The image is normalized so it is less sensitive to brightness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "def norm_im(img): ##, testimage):\n",
    "   input_mean = 0 #128\n",
    "   input_std = 255 #128\n",
    "\n",
    "   input_name = \"file_reader\"\n",
    "   output_name = \"normalized\"\n",
    "   #img = imread(image_path)\n",
    "   nx, ny, nz = np.shape(img)\n",
    "\n",
    "   theta = np.std(img).astype('int')\n",
    "   #try:\n",
    "   #   file_reader = tf.read_file(testimage, input_name)\n",
    "   #   image_reader = tf.image.decode_jpeg(file_reader, channels = 3,\n",
    "   #                                     name='jpeg_reader')\n",
    "   #   float_caster = tf.cast(image_reader, tf.float32)  \n",
    "   #except:\n",
    "   float_caster = tf.cast(img, tf.float32)\n",
    "   \n",
    "   dims_expander = tf.expand_dims(float_caster, 0);\n",
    "   normalized = tf.divide(tf.subtract(dims_expander, [input_mean]), [input_std])\n",
    "   sess = tf.Session()\n",
    "   return np.squeeze(sess.run(normalized))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CRF function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "def getCRF(image, Lc, theta, n_iter, label_lines, compat_spat=12, compat_col=40, scale=5, prob=0.5):\n",
    "\n",
    "#        n_iters: number of iterations of MAP inference.\n",
    "#        sxy_gaussian: standard deviations for the location component\n",
    "#            of the colour-independent term.\n",
    "#        compat_gaussian: label compatibilities for the colour-independent\n",
    "#            term (can be a number, a 1D array, or a 2D array).\n",
    "#        kernel_gaussian: kernel precision matrix for the colour-independent\n",
    "#            term (can take values CONST_KERNEL, DIAG_KERNEL, or FULL_KERNEL).\n",
    "#        normalisation_gaussian: normalisation for the colour-independent term\n",
    "#            (possible values are NO_NORMALIZATION, NORMALIZE_BEFORE, NORMALIZE_AFTER, NORMALIZE_SYMMETRIC).\n",
    "#        sxy_bilateral: standard deviations for the location component of the colour-dependent term.\n",
    "#        compat_bilateral: label compatibilities for the colour-dependent\n",
    "#            term (can be a number, a 1D array, or a 2D array).\n",
    "#        srgb_bilateral: standard deviations for the colour component\n",
    "#            of the colour-dependent term.\n",
    "#        kernel_bilateral: kernel precision matrix for the colour-dependent term\n",
    "#            (can take values CONST_KERNEL, DIAG_KERNEL, or FULL_KERNEL).\n",
    "#        normalisation_bilateral: normalisation for the colour-dependent term\n",
    "#            (possible values are NO_NORMALIZATION, NORMALIZE_BEFORE, NORMALIZE_AFTER, NORMALIZE_SYMMETRIC).\n",
    "\n",
    "      H = image.shape[0]\n",
    "      W = image.shape[1]\n",
    "\n",
    "      d = dcrf.DenseCRF2D(H, W, len(label_lines)+1)\n",
    "      U = unary_from_labels(Lc.astype('int'), len(label_lines)+1, gt_prob= prob)\n",
    "\n",
    "      d.setUnaryEnergy(U)\n",
    "\n",
    "      del U\n",
    "\n",
    "      # This potential penalizes small pieces of segmentation that are\n",
    "      # spatially isolated -- enforces more spatially consistent segmentations\n",
    "      # This adds the color-independent term, features are the locations only.\n",
    "      # sxy = The scaling factors per dimension.\n",
    "      d.addPairwiseGaussian(sxy=(theta,theta), compat=compat_spat, kernel=dcrf.DIAG_KERNEL, #compat=6\n",
    "                      normalization=dcrf.NORMALIZE_SYMMETRIC)\n",
    "\n",
    "      # sdims = The scaling factors per dimension.\n",
    "      # schan = The scaling factors per channel in the image.\n",
    "      # This creates the color-dependent features and then add them to the CRF\n",
    "      feats = create_pairwise_bilateral(sdims=(theta, theta), schan=(scale, scale, scale), #11,11,11\n",
    "                                  img=image, chdim=2)\n",
    "\n",
    "      del image\n",
    "\n",
    "      d.addPairwiseEnergy(feats, compat=compat_col, #20\n",
    "                    kernel=dcrf.DIAG_KERNEL,\n",
    "                    normalization=dcrf.NORMALIZE_SYMMETRIC)\n",
    "      del feats\n",
    "\n",
    "      Q = d.inference(n_iter)\n",
    "\n",
    "      #preds = np.array(Q, dtype=np.float32).reshape(\n",
    "      #  (len(label_lines)+1, nx, ny)).transpose(1, 2, 0)\n",
    "      #preds = np.expand_dims(preds, 0)\n",
    "      #preds = np.squeeze(preds)\n",
    "\n",
    "      return np.argmax(Q, axis=0).reshape((H, W)) #, preds#, p, R, d.klDivergence(Q),\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up the analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "User-defined settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tile = 96\n",
    "winprop = 1.0\n",
    "prob_thres = 0.5\n",
    "n_iter = 30\n",
    "compat_col = 100\n",
    "theta = 60 #100\n",
    "scale = 1\n",
    "decim = 8\n",
    "fct =  0.25 \n",
    "compat_spat = 5\n",
    "prob = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Labels and tensorflow graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_path = 'ontario_labels.txt'  \n",
    "classifier_file = 'ontario_test_mobilenetv2_96_100_0.01.pb' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to define a file that contains colors for each class in the labels file.\n",
    "\n",
    "First, let's remind ourselves of the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat ontario_labels.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define colors in the correct order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['r', 'w', 'm', 'g', 'b']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ontario_colors.txt', 'a') as the_file:\n",
    "    for c in colors:\n",
    "        the_file.write(c+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors_path = 'ontario_colors.txt'    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat $colors_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use html codes for more custom colors\n",
    "\n",
    "https://www.w3schools.com/colors/colors_picker.asp\n",
    "\n",
    "https://www.w3schools.com/colors/colors_names.asp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm $colors_path\n",
    "cols = ['#A52A2A', '#FFD700', '#808000', '#00FF7F', '#4682B4']\n",
    "\n",
    "with open('ontario_colors.txt', 'a') as the_file:\n",
    "    for c in colors:\n",
    "        the_file.write(c+'\\n')\n",
    "        \n",
    "!cat $colors_path        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This next part loads the labels and colors and creates a colormap for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loads label file, strips off carriage return\n",
    "labels = [line.rstrip() for line \n",
    "                in tf.gfile.GFile(labels_path)]\n",
    "\n",
    "code= {}\n",
    "for label in labels:\n",
    "   code[label] = [i for i, x in enumerate([x.startswith(label) for x in labels]) if x].pop()\n",
    "\n",
    "with open(colors_path) as f: #'labels.txt') as f:\n",
    "   cols = f.readlines()\n",
    "cmap1 = [x.strip() for x in cols] \n",
    " \n",
    "classes = dict(zip(labels, cmap1))\n",
    "\n",
    "cmap1 = colors.ListedColormap(cmap1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read file in (local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testimage = 'train/201300025.JPG'\n",
    "img = imread(testimage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read file (S3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import s3fs\n",
    "fs = s3fs.S3FileSystem(anon=True)\n",
    "testimage = fs.ls('cdi-workshop/semseg_data/ontario/test/')[0]\n",
    "with fs.open(testimage, 'rb') as f:\n",
    "    img = imread(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nxo, nyo, nzo = np.shape(img)\n",
    "result = norm_im(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pad image using mirroring and create tiles by using sliding window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## pad image so it is divisible by N windows with no remainder \n",
    "result = np.vstack((np.hstack((result,np.fliplr(result))), np.flipud(np.hstack((result,np.fliplr(result))))))\n",
    "result = result[:nxo+np.mod(nxo,tile),:nyo+np.mod(nyo,tile), :] \n",
    "\n",
    "nx, ny, nz = np.shape(result)\n",
    "\n",
    "gridy, gridx = np.meshgrid(np.arange(ny), np.arange(nx))\n",
    "Zx,_ = sliding_window(gridx, (tile,tile), (tile,tile))\n",
    "Zy,_ = sliding_window(gridy, (tile,tile), (tile,tile))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each window, estimate the class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if decim>1:\n",
    "   Zx = Zx[::decim]\n",
    "   Zy = Zy[::decim]\n",
    "\n",
    "print('CNN ... ')\n",
    "graph = load_graph(classifier_file)\n",
    "\n",
    "w1 = []\n",
    "Z,ind = sliding_window(result, (tile,tile,3), (tile, tile,3))\n",
    "if decim>1:\n",
    "   Z = Z[::decim]\n",
    "for i in range(len(Z)):\n",
    "   w1.append(getCP(Z[i], graph))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create output arrays, filter out tiles with low probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##C=most likely, P=prob, PP=all probs\n",
    "C, P, PP = zip(*w1)\n",
    "\n",
    "del w1\n",
    "\n",
    "C = np.asarray(C)\n",
    "P = np.asarray(P)\n",
    "PP = np.asarray(PP)\n",
    "\n",
    "C = C+1 #add 1 so all labels are >=1\n",
    "PP = np.squeeze(PP)\n",
    "\n",
    "## create images with classes and probabilities\n",
    "Lc = np.zeros((nx, ny))\n",
    "Lp = np.zeros((nx, ny))\n",
    "\n",
    "mn = np.int(tile-(tile*winprop)) #tile/2 - tile/4)\n",
    "mx = np.int(tile+(tile*winprop)) #tile/2 + tile/4)\n",
    "\n",
    "for k in range(len(Zx)): \n",
    "   Lc[Zx[k][mn:mx,mn:mx], Zy[k][mn:mx,mn:mx]] = Lc[Zx[k][mn:mx,mn:mx], Zy[k][mn:mx,mn:mx]]+C[k] \n",
    "   Lp[Zx[k][mn:mx,mn:mx], Zy[k][mn:mx,mn:mx]] = Lp[Zx[k][mn:mx,mn:mx], Zy[k][mn:mx,mn:mx]]+P[k] \n",
    "\n",
    "Lpp = np.zeros((nx, ny, np.shape(PP)[1]))\n",
    "for k in range(len(Zx)): \n",
    "   for l in range(np.shape(PP)[1]):\n",
    "      Lpp[Zx[k], Zy[k], l] = Lpp[Zx[k], Zy[k], l]+PP[k][l]\n",
    "\n",
    "Lpp = Lpp[:nxo, :nyo, :]      \n",
    "Lp = Lp[:nxo, :nyo]      \n",
    "Lc = Lc[:nxo, :nyo]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lcorig = Lc.copy()\n",
    "Lcorig[Lp < prob_thres] = np.nan\n",
    "\n",
    "Lc[np.isnan(Lcorig)] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to resize to speed things up a little"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgr = imresize(img, fct)\n",
    "Lcr = np.round(imresize(Lc, fct, interp='nearest')/255 * np.max(Lc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(imgr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(Lcr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conditional Random Field post-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('CRF ... ')\n",
    "res = getCRF(imgr, Lcr.astype('int'), theta, n_iter, labels, compat_spat, compat_col, scale, prob)\n",
    "\n",
    "del imgr\n",
    "resr = np.round(imresize(res, 1/fct, interp='nearest')/255 * np.max(res))\n",
    "   \n",
    "code1 = np.unique(res)\n",
    "code2 = np.unique(resr)   \n",
    "resrr = np.zeros(np.shape(resr), dtype='int8')\n",
    "for kk in range(len(code1)):\n",
    "   resrr[resr==code2[kk]] = code1[kk]   \n",
    "   \n",
    "del res, resr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we can plot the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,15))\n",
    "fig.subplots_adjust(wspace=0.4)\n",
    "ax1 = fig.add_subplot(131)\n",
    "ax1.get_xaxis().set_visible(False)\n",
    "ax1.get_yaxis().set_visible(False)\n",
    "\n",
    "im = ax1.imshow(img)\n",
    "plt.title('a) Input', loc='left', fontsize=6)\n",
    "\n",
    "ax1 = fig.add_subplot(132)\n",
    "ax1.get_xaxis().set_visible(False)\n",
    "ax1.get_yaxis().set_visible(False)\n",
    "\n",
    "im = ax1.imshow(img)\n",
    "plt.title('b) CNN prediction', loc='left', fontsize=6)\n",
    "im2 = ax1.imshow(Lcorig-1, cmap=cmap1, alpha=0.5, vmin=0, vmax=len(labels))\n",
    "divider = make_axes_locatable(ax1)\n",
    "cax = divider.append_axes(\"right\", size=\"5%\")\n",
    "cb=plt.colorbar(im2, cax=cax)\n",
    "cb.set_ticks(.5+np.arange(len(labels)+1)) \n",
    "cb.ax.set_yticklabels(labels)\n",
    "cb.ax.tick_params(labelsize=4) \n",
    "plt.axis('tight')\n",
    "\n",
    "ax1 = fig.add_subplot(133)\n",
    "ax1.get_xaxis().set_visible(False)\n",
    "ax1.get_yaxis().set_visible(False)\n",
    "\n",
    "im = ax1.imshow(img)\n",
    "plt.title('c) CRF prediction', loc='left', fontsize=6)\n",
    "im2 = ax1.imshow(resrr, cmap=cmap1, alpha=0.5, vmin=0, vmax=len(labels))\n",
    "divider = make_axes_locatable(ax1)\n",
    "cax = divider.append_axes(\"right\", size=\"5%\")\n",
    "cb=plt.colorbar(im2, cax=cax)\n",
    "cb.set_ticks(.5+np.arange(len(labels)+1)) \n",
    "cb.ax.set_yticklabels(labels)\n",
    "cb.ax.tick_params(labelsize=4)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
