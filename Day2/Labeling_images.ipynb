{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Label Images "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Written by Dr Daniel Buscombe, Northern Arizona University\n",
    "\n",
    "> Part of a series of notebooks for image recognition and classification using deep convolutional neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates how to create a ground truth (label) image using a weakly supervised conditional random field"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is something we can't do in the notebook because it involves interacting with graphics. So, you'll be running this on your laptop "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The script is part of the ```dl_tools``` package. The syntax is:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python label_1image_crf.py -w 500 -s 0.125```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* -w : window size in pixels\n",
    "* -s : size of image for CRF "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. conda activate tfpy35\n",
    "2. navigate to dl_tools \n",
    "3. cd create_groundtruth\n",
    "3. ```python label_1image_crf.py -w 500 -s 0.125```\n",
    "4. You will first be prompted to select an image to work on\n",
    "5. Next, you will be promted to select a labels file\n",
    "6. Finally, you will be prompted to select a colors file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On each chunk, cycling through a pre-defined set of classes, you will be prompted to draw (using the cursor) example regions of the image that correspond to each label. \n",
    "\n",
    "These annotations should be exemplative, i.e., a relatively small portion of the region in the chunk that pertains to the class, rather than delimiting the entire region within the chunk that pertains to the class. \n",
    "\n",
    "Typically, the CRF algorithm only requires a few example annotations for each class. \n",
    "\n",
    "For very heterogeneous scenes, however, where each class occurs in several regions across the image, example annotations should be provided for each class in each region where that class occurs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll select an image from the [Google Drive](https://drive.google.com/open?id=1IhStVBhWMKLZUWIprti6zZyOg32-W4Of)\n",
    "\n",
    "* The images are located in semseg_data/Monterey_scarps/test. We'll use [this one](https://drive.google.com/open?id=1ZVYXp4h6dtduhCyliNVFrgbW9jkSENer)\n",
    "\n",
    "* The labels are located in semseg_data/Monterey_scarps/labels. We'll use [this one](https://drive.google.com/open?id=1XYkpKZmu1jZsQX72b_FlxKyvMyOxqn5O)\n",
    "\n",
    "* The label colors are located in semseg_data/Monterey_scarps/labels. We'll use [this one](https://drive.google.com/open?id=1pKCLUSdeW1EDQMYUcpEOdheDAdYlRogl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "python label_1image_crf.py -w 500 -s 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](http://www.mdpi.com/geosciences/geosciences-08-00244/article_deploy/html/images/geosciences-08-00244-g001.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this information, the CRF algorithm estimates the class of each pixel in the image. \n",
    "\n",
    "CRF inference time depends primarily on image complexity and size, but is also secondarily affected by the number and spatial heterogeneity of the class labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "dat = loadmat('')\n",
    "dat.keys()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
